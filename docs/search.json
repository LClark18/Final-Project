[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Logan Clark 437 Final",
    "section": "",
    "text": "Hello my name is Logan Clark and I’m a 4th year here at Cal State University Fullerton and this is my final project for my Math 437: Modern Data Analysis class."
  },
  {
    "objectID": "index.html#motivation-and-context",
    "href": "index.html#motivation-and-context",
    "title": "Logan Clark 437 Final",
    "section": "Motivation and Context",
    "text": "Motivation and Context\nFor my project I decided to look at the sales of Video Games. Video Games have been my main hobby for most of my life and I’ve always had an innate interest in sales numbers. I would go on Wikipedia just to look at the list of best selling games and see what changes would be happening on the chart on a weekly basis. Each game would have it’s own entry and show us what console it came out on, when it came out, etc. It makes me wonder if there’s any common trends among games that have higher sales overall, such as if a specific genre is more appealing, or if games on a certain console did better than others."
  },
  {
    "objectID": "index.html#main-objective",
    "href": "index.html#main-objective",
    "title": "Logan Clark 437 Final",
    "section": "Main Objective",
    "text": "Main Objective\nMy main Objective for this project is to use clustering to see what games are similar and to see if we can see any patterns among games in the cluster that contains higher global sales."
  },
  {
    "objectID": "index.html#data-description",
    "href": "index.html#data-description",
    "title": "Logan Clark 437 Final",
    "section": "Data Description",
    "text": "Data Description\n\nData Limitations\nThe data only contains data until about 2016, so the data set itself is old and needs to be updated"
  },
  {
    "objectID": "index.html#data-wrangling-optional-section",
    "href": "index.html#data-wrangling-optional-section",
    "title": "Logan Clark 437 Final",
    "section": "Data Wrangling (Optional Section)",
    "text": "Data Wrangling (Optional Section)"
  },
  {
    "objectID": "index.html#exploratory-data-analysis",
    "href": "index.html#exploratory-data-analysis",
    "title": "Logan Clark 437 Final",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis"
  },
  {
    "objectID": "index.html#insights",
    "href": "index.html#insights",
    "title": "Logan Clark 437 Final",
    "section": "Insights",
    "text": "Insights\n\nLimitations and Future Work\n\n\nReflection (Optional Subsection)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Data Wrangling and Modeling",
    "section": "",
    "text": "library(GGally)\nlibrary(tidyverse)\nlibrary(tidyclust)\nlibrary(broom)\nlibrary(mclust)\nlibrary(tidymodels)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nGGally to get the ggpairs function tidyclust to specify clustering models Broom to Convert Statistical Objects into Tidy Tibbles mclust for model based clustering dplyr to massage and summarize data tidymodels for modeling tidyverse for piping and altering data ggplot2 for graphs in eda and clustering"
  },
  {
    "objectID": "about.html#packages-used-in-this-analysis",
    "href": "about.html#packages-used-in-this-analysis",
    "title": "Data Wrangling and Modeling",
    "section": "",
    "text": "library(GGally)\nlibrary(tidyverse)\nlibrary(tidyclust)\nlibrary(broom)\nlibrary(mclust)\nlibrary(tidymodels)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nGGally to get the ggpairs function tidyclust to specify clustering models Broom to Convert Statistical Objects into Tidy Tibbles mclust for model based clustering dplyr to massage and summarize data tidymodels for modeling tidyverse for piping and altering data ggplot2 for graphs in eda and clustering"
  },
  {
    "objectID": "about.html#data-description",
    "href": "about.html#data-description",
    "title": "Data Wrangling and Modeling",
    "section": "Data Description",
    "text": "Data Description\n\nvgsales &lt;- readr::read_csv(\"C:/Users/19493/Desktop/vgsales.csv\")\n\nI got the dataset from a site called Kaggle.com and the data set analyzes sales data from over 16,000 games that had more than 100,000 global sales. The data itself was generated by a scrape of vgchartz.com, which is another website that goes into deep analysis about video games sales.\nThe Data has 11 different variables Rank is a games placement in sales, Name is the name of the game, Platform is which console said game came out on, Genre is the genre of the game, Publisher is who published the game, and the different Sales columns relate to how many copies the game sole in North America, Europe, Japan, all other territories, and final how many total copies were sold globally."
  },
  {
    "objectID": "about.html#eda",
    "href": "about.html#eda",
    "title": "Data Wrangling and Modeling",
    "section": "EDA",
    "text": "EDA\n\nvgsales &lt;- vgsales %&gt;%\n  filter(Global_Sales &gt; 1) %&gt;%\n  mutate(log_sales = log(Global_Sales)) %&gt;%\nmutate(NA_log_sales = log(NA_Sales + 0.01)) %&gt;%\nmutate(EU_log_sales = log(EU_Sales + 0.01)) %&gt;%\nmutate(JP_log_sales = log(JP_Sales + 0.01)) %&gt;%\nmutate(OT_log_sales = log(Other_Sales + 0.1)) %&gt;%\n  mutate(Platform = as.factor(Platform) |&gt;\nfct_collapse(\n  Sony = c(\"PS\", \"PS2\", \"PS3\", \"PS4\", \"PSP\", \"PSV\"),\n  Microsoft = c(\"X360\", \"XB\", \"XOne\"),\n  Nintendo = c(\"NES\", \"SNES\", \"Wii\", \"WiiU\", \"GC\", \"N64\", \"3DS\", \"DS\", \"GB\", \"GBA\"),\n  Other = c(\"2600\", \"DC\", \"GEN\", \"PC\", \"SAT\", \"SCD\")\n))\n\n\nggplot(data = vgsales,\n       aes(x = Year, y = Global_Sales)) + geom_boxplot()\n\n\n\n\n\n\n\n\n\nggplot(data = vgsales,\n       aes(x = Year, y = log_sales)) + geom_boxplot()"
  },
  {
    "objectID": "about.html#modeling",
    "href": "about.html#modeling",
    "title": "Data Wrangling and Modeling",
    "section": "Modeling",
    "text": "Modeling\n\nvg_split &lt;- initial_split(vgsales, prop = 0.75) \n\nvg_train &lt;- training(vg_split)\nvg_test &lt;- testing(vg_split)\n\n\nkmeans_recipe_fv &lt;- recipe(~ log_sales + NA_log_sales + EU_log_sales + JP_log_sales + OT_log_sales + Platform + Genre, \n                           data = vg_train) |&gt;\n  step_YeoJohnson(all_numeric_predictors()) |&gt; # deal with skew issues\n  step_normalize(all_numeric_predictors()) |&gt; # deal with different variances\n  step_dummy(all_nominal_predictors(), one_hot = TRUE) |&gt; \n  step_zv(all_predictors())\n\nThis is the recipe used for Kmeans clustering\n\nkmeans_model &lt;- k_means(num_clusters = tune()) |&gt;\n  set_args(nstart = 20)\n\nThe cluster model\n\nkmeans_wflow_fv &lt;- workflow() |&gt;\n  add_model(kmeans_model) |&gt;\n  add_recipe(kmeans_recipe_fv)\n\n\nset.seed(1002)\nfv_kfold_tidy &lt;- vfold_cv(vg_train, v = 5, repeats = 1) \nnclusters_grid &lt;- data.frame(num_clusters = seq(1, 10))\n\nkmeans_tuned_fv &lt;- tune_cluster(kmeans_wflow_fv,\n                                resamples = fv_kfold_tidy,\n                                metrics = cluster_metric_set(sse_total, \n                                                             sse_within_total, sse_ratio),\n                                grid = nclusters_grid)\n\n! Fold5: preprocessor 1/1, model 8/10: did not converge in 10 iterations\n\ntuned_metrics &lt;- collect_metrics(kmeans_tuned_fv)\n\ntuned_metrics |&gt;\n  arrange(desc(.metric), num_clusters) |&gt;\n  select(num_clusters, .metric, mean, everything())\n\n# A tibble: 30 × 7\n   num_clusters .metric           mean .estimator     n std_err .config         \n          &lt;int&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;      &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           \n 1            1 sse_within_total 8060. standard       5    1.51 Preprocessor1_M…\n 2            2 sse_within_total 5852. standard       5    9.16 Preprocessor1_M…\n 3            3 sse_within_total 4862. standard       5   14.8  Preprocessor1_M…\n 4            4 sse_within_total 4409. standard       5   14.9  Preprocessor1_M…\n 5            5 sse_within_total 4032. standard       5   20.4  Preprocessor1_M…\n 6            6 sse_within_total 3771. standard       5   13.9  Preprocessor1_M…\n 7            7 sse_within_total 3541. standard       5   16.8  Preprocessor1_M…\n 8            8 sse_within_total 3373. standard       5   15.2  Preprocessor1_M…\n 9            9 sse_within_total 3220. standard       5   10.4  Preprocessor1_M…\n10           10 sse_within_total 3092. standard       5   13.1  Preprocessor1_M…\n# ℹ 20 more rows\n\n\n\ntuned_metrics |&gt;\n  filter(.metric == \"sse_ratio\") |&gt;\n  ggplot(aes(x = num_clusters, y = mean)) +\n  geom_point() + \n  geom_line() +\n  labs(x = \"Number of Clusters\", y = \"Mean WSS/TSS (5 folds)\") +\n  scale_x_continuous(breaks = seq(1, 10))\n\n\n\n\n\n\n\n\n\nkmeans_fv_3clusters &lt;- kmeans_wflow_fv |&gt;\n  finalize_workflow_tidyclust(parameters = list(num_clusters = 3))\n\n\nset.seed(1002) \n# always reset the seed before you re-fit, just in case something weird happens\n\nkmeans_fv_fit3 &lt;- kmeans_fv_3clusters |&gt;\n  fit(data = vg_train)\n\n\nvg3 &lt;- bind_cols(\n  vg_train,\n  kmeans_fv_fit3 |&gt; extract_cluster_assignment())\n\nvg3 |&gt;\n  select(Name, .cluster, everything())\n\n# A tibble: 1,540 × 17\n   Name          .cluster  Rank Platform Year  Genre Publisher NA_Sales EU_Sales\n   &lt;chr&gt;         &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1 ATV: Quad Po… Cluster…  1996 Sony     2000  Raci… Acclaim …     0.58     0.39\n 2 Die Hard Tri… Cluster…  1218 Sony     1996  Shoo… Fox Inte…     0.85     0.58\n 3 Destiny: The… Cluster…   907 Sony     2015  Shoo… Activisi…     0.77     0.78\n 4 ESPN NFL 2K5  Cluster…  1125 Microso… 2004  Spor… Sega          1.54     0.02\n 5 Mario Party … Cluster…  1209 Nintendo 2015  Misc  Nintendo      0.69     0.5 \n 6 NASCAR Thund… Cluster…  1751 Sony     2001  Raci… Electron…     0.57     0.44\n 7 Metroid       Cluster…   549 Nintendo 1986  Acti… Nintendo      1.33     0.31\n 8 Chocobo no F… Cluster…  1645 Sony     1997  Role… SquareSo…     0        0   \n 9 Just Dance 3  Cluster…    61 Nintendo 2011  Misc  Ubisoft       6.05     3.15\n10 Major League… Cluster…  1284 Sony     2005  Spor… Take-Two…     0.72     0.56\n# ℹ 1,530 more rows\n# ℹ 8 more variables: JP_Sales &lt;dbl&gt;, Other_Sales &lt;dbl&gt;, Global_Sales &lt;dbl&gt;,\n#   log_sales &lt;dbl&gt;, NA_log_sales &lt;dbl&gt;, EU_log_sales &lt;dbl&gt;,\n#   JP_log_sales &lt;dbl&gt;, OT_log_sales &lt;dbl&gt;\n\n\n\nlibrary(GGally)\nggpairs(vg3, columns = c(\"log_sales\", \"NA_log_sales\", \"EU_log_sales\", \"JP_log_sales\", \"OT_log_sales\", \"Platform\", \"Genre\"),\n        aes(color = .cluster))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nvg_predictions3 &lt;- augment(kmeans_fv_fit3, \n                        new_data = vg_test)\n\nggpairs(vg_predictions3, columns = c(\"log_sales\", \"NA_log_sales\", \"EU_log_sales\", \"JP_log_sales\", \"OT_log_sales\", \"Platform\", \"Genre\"),\n        aes(color = .pred_cluster))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nvg_all_clusters3 &lt;- bind_rows(\n  vg3,\n  vg_predictions3 |&gt; rename(.cluster = .pred_cluster) # rename cluster variable name\n)\n\n\nggplot(data = vg_all_clusters3, mapping = aes(x = log_sales, fill = .cluster)) + geom_density()\n\n\n\n\n\n\n\n\n\nggplot(data = vg_all_clusters3, mapping = aes(x = NA_log_sales, fill = .cluster)) + geom_density()\n\n\n\n\n\n\n\n\n\nggplot(data = vg_all_clusters3, mapping = aes(x = EU_log_sales, fill = .cluster)) + geom_density()\n\n\n\n\n\n\n\n\n\nggplot(data = vg_all_clusters3, mapping = aes(x = JP_log_sales, fill = .cluster)) + geom_density()\n\n\n\n\n\n\n\n\n\nggplot(data = vg_all_clusters3, mapping = aes(x = OT_log_sales, fill = .cluster)) + geom_density()\n\n\n\n\n\n\n\n\n\nggplot(data = vg_all_clusters3, mapping = aes(x = Platform, fill = .cluster)) + geom_bar()\n\n\n\n\n\n\n\n\n\nggplot(data = vg_all_clusters3, mapping = aes(x = Genre, fill = .cluster)) + geom_bar()"
  },
  {
    "objectID": "Final-Project/Codes.html",
    "href": "Final-Project/Codes.html",
    "title": "Code",
    "section": "",
    "text": "Code Chunks for the website"
  }
]